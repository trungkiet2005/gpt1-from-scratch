{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset:  83454369\n",
      "thơ lục bát: \n",
      " ai ơi xa bến quê hương\n",
      "nhớ về quê mẹ nắng sương đây nè\n",
      "nhớ sao những buổi trưa hè\n",
      "võng đưa cót két gió hè hiu hiu\n",
      "lời ru của mẹ dấu yêu\n",
      "ngọt ngào êm dịu mẹ yêu con nhiều\n",
      "lời mẹ năm tháng sớm chiều\n",
      "con nghe nhớ mãi những điều ru ta\n",
      "lòng mẹ ôi thật bao la\n",
      "thái bình rộng lớn thương là mênh mông\n",
      "một đời lưng mẹ đã còng\n",
      "vai mang tay xách lo chồng chăm con\n",
      "mong sao con lớn nên người\n",
      "thân mẹ có cực vẫn cười thương con\n",
      "vì đời mẹ sống cho con\n",
      "gom bao mệt nhọc mãi còn vòng tay\n",
      "mong chờ cho đến một ngày\n",
      "công thành danh toại là ngày mẹ mong\n",
      "dù nay mẹ đã xa rồi\n",
      "con đây nhớ mãi mẹ ôi vạn lần\n",
      "nguyện rằng ghi nhớ công ân\n",
      "sinh thành dưỡng dục mẫu thân đời đời\n",
      "thơ lục bát: \n",
      " mùa đông để mộng nằm im\n",
      "bao nhiêu nỗi nhớ biết tìm nơi đâu\n",
      "trăng bơ vơ lạnh mái đầu\n",
      "tuyết rơi bông nhớ gió sầu khúc ru\n",
      "\n",
      "một mình lẻ bóng phiêu du\n",
      "một mình thổn thức tâm tư quê người\n",
      "tiếc giọt nắng tuổi đôi mươi\n",
      "rơi trên thềm mộng cuộc đời trắng trong\n",
      "\n",
      "nhớ ngọn gió bế tuổi hồng\n",
      "hương hoa thơm ngát tỏa trong câu thề\n",
      "để \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "with open(\"dataset.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "print(\"Length of dataset: \", len(text))\n",
    "\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\n",
      " 0123456789:=`abcdefghijklmnopqrstuvwxyz|~¡¢¤¥¬­°²³´µ¸¹àáâãäåçèéêëìíîïñòóôõöøùúûüýÿāăąćđēęěĩīńōœšťũūůơƣưǎǒǚǵṇ̀̀́̂̃̉γсцḥḷḿṃṇṕṭạảấầẩẫậắằẳẵặẹẻẽếềểễệỉịọỏốồổỗộớờởỡợụủứừửữựỳỵỷỹ​‌‍‎₫◇❄❣❤。️﻿，￼🍁🍂💋😉😔😥😧🤣\n",
      "194\n",
      "[29, 23, 156, 2, 37, 143, 2, 32, 36, 66, 2, 23, 105, 103, 29, 22]\n",
      "nhớ về quê hương\n",
      "torch.Size([83454369]) torch.int64\n",
      "tensor([ 35,  23, 103,   2,  27, 161,  18,   2,  17,  58,  35,  13,   2,   1,\n",
      "          2,  16,  24,   2, 103,  24,   2,  39,  16,   2,  17, 142,  29,   2,\n",
      "         32,  36,  66,   2,  23, 105, 103,  29,  22,   1,  29,  23, 156,   2,\n",
      "         37, 143,   2,  32,  36,  66,   2,  28, 139,   2,  29, 134,  29,  22,\n",
      "          2,  34, 105, 103,  29,  22,   2,  89,  59,  40,   2,  29,  64,   1,\n",
      "         29,  23, 156,   2,  34,  16,  30,   2,  29,  23, 166,  29,  22,   2,\n",
      "         17,  36, 153,  24,   2,  35,  33, 105,  16,   2,  23,  64,   1,  37,\n",
      "         76,  29])\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)\n",
    "\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])\n",
    "\n",
    "print(encode(\"nhớ về quê hương\"))\n",
    "print(decode(encode(\"nhớ về quê hương\")))\n",
    "\n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 35,  23, 103,   2,  27, 161,  18,   2,  17])\n",
      "when input is tensor([35]) the target is 23\n",
      "when input is tensor([35, 23]) the target is 103\n",
      "when input is tensor([ 35,  23, 103]) the target is 2\n",
      "when input is tensor([ 35,  23, 103,   2]) the target is 27\n",
      "when input is tensor([ 35,  23, 103,   2,  27]) the target is 161\n",
      "when input is tensor([ 35,  23, 103,   2,  27, 161]) the target is 18\n",
      "when input is tensor([ 35,  23, 103,   2,  27, 161,  18]) the target is 2\n",
      "when input is tensor([ 35,  23, 103,   2,  27, 161,  18,   2]) the target is 17\n"
     ]
    }
   ],
   "source": [
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "block_size = 8\n",
    "print(train_data[:block_size+1])\n",
    "\n",
    "x = train_data[:block_size+1]\n",
    "y = train_data[1:block_size+1]\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = x[:t + 1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target is {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[  2,  18,  23, 148,  36,   2,  89,  74],\n",
      "        [ 74,  29,  22,   2,  29,  22, 130,  28],\n",
      "        [ 28,   2,  18, 105, 157,  24,   2,  27],\n",
      "        [157,  24,   2,  35,  74,  18,   2,  39]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "--------------------------------\n",
      "when input is tensor([2]) the target is 18\n",
      "when input is tensor([ 2, 18]) the target is 23\n",
      "when input is tensor([ 2, 18, 23]) the target is 148\n",
      "when input is tensor([  2,  18,  23, 148]) the target is 36\n",
      "when input is tensor([  2,  18,  23, 148,  36]) the target is 2\n",
      "when input is tensor([  2,  18,  23, 148,  36,   2]) the target is 89\n",
      "when input is tensor([  2,  18,  23, 148,  36,   2,  89]) the target is 74\n",
      "when input is tensor([  2,  18,  23, 148,  36,   2,  89,  74]) the target is 24\n",
      "when input is tensor([74]) the target is 29\n",
      "when input is tensor([74, 29]) the target is 22\n",
      "when input is tensor([74, 29, 22]) the target is 2\n",
      "when input is tensor([74, 29, 22,  2]) the target is 29\n",
      "when input is tensor([74, 29, 22,  2, 29]) the target is 22\n",
      "when input is tensor([74, 29, 22,  2, 29, 22]) the target is 130\n",
      "when input is tensor([ 74,  29,  22,   2,  29,  22, 130]) the target is 28\n",
      "when input is tensor([ 74,  29,  22,   2,  29,  22, 130,  28]) the target is 2\n",
      "when input is tensor([28]) the target is 2\n",
      "when input is tensor([28,  2]) the target is 18\n",
      "when input is tensor([28,  2, 18]) the target is 105\n",
      "when input is tensor([ 28,   2,  18, 105]) the target is 157\n",
      "when input is tensor([ 28,   2,  18, 105, 157]) the target is 24\n",
      "when input is tensor([ 28,   2,  18, 105, 157,  24]) the target is 2\n",
      "when input is tensor([ 28,   2,  18, 105, 157,  24,   2]) the target is 27\n",
      "when input is tensor([ 28,   2,  18, 105, 157,  24,   2,  27]) the target is 57\n",
      "when input is tensor([157]) the target is 24\n",
      "when input is tensor([157,  24]) the target is 2\n",
      "when input is tensor([157,  24,   2]) the target is 35\n",
      "when input is tensor([157,  24,   2,  35]) the target is 74\n",
      "when input is tensor([157,  24,   2,  35,  74]) the target is 18\n",
      "when input is tensor([157,  24,   2,  35,  74,  18]) the target is 2\n",
      "when input is tensor([157,  24,   2,  35,  74,  18,   2]) the target is 39\n",
      "when input is tensor([157,  24,   2,  35,  74,  18,   2,  39]) the target is 16\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch(\"train\")\n",
    "print(\"inputs:\")\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print(\"targets:\")\n",
    "print(yb.shape)\n",
    "\n",
    "print('--------------------------------')\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t]\n",
    "        print(f\"when input is {context} the target is {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets = None):\n",
    "\n",
    "        logits = self.token_embedding_table(idx)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "            return logits, loss\n",
    "\n",
    "        B, T, C = logits.shape\n",
    "        logits = logits.view(B*T, C)\n",
    "        targets = targets.view(B*T)\n",
    "        loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 194])\n",
      "tensor(5.9145, grad_fn=<NllLossBackward0>)\n",
      "\ḅskữćêỷằørãećợ2ả￼ťēàöů😔`γrcỷ`îừxẽẻ~¹ǵđ😉m77zцệ‌êỹ¬ừwц²ẽñạăụ😉ạ̈ợ´²5ṃẹëñǒ🍂ǒ‍snçậ¢p7ặǎ¢😉ứõ̀ừ=ýäạḿàứàễé\n"
     ]
    }
   ],
   "source": [
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "idx = torch.zeros((1, 1), dtype=torch.long)\n",
    "print(decode(m.generate(idx, 100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "for steps in range(100):\n",
    "    xb, yb = get_batch()\n",
    "    \n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(loss.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
